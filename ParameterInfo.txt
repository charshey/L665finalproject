SVM/kernel	weighted	accuracy	precision	recall	f-score
LinearSVC	no	0.779221	0.8338726	0.8259	0.829639
LinearSVC	yes	0.685065	0.8157468	0.7779	0.7627019
SVClinear	yes	0.720779	0.8364935	0.7994	0.80515
SVCrbf	yes	0.577922	0.641399	0.624689	0.6193837
SVCpoly	yes	0.7240259	0.61528907	0.67156939	0.6200403
SVCsigmoid	yes	0.483766	0.5194605	0.51708213	0.5020411
SVClinear	no	0.7662337	0.82825449	0.819153296	0.8233087
SVCrbf	no	0.7207792	0.5704723586	0.659794474912	0.556513628507
SVCpoly	no	.75	0.534022931347	0.695176348548	0.481820233133
SVCsigmoid	no	0.577922077922	0.507816888276	0.507642752562	0.507601215479
Nulinear	n/a	0.746753246753	0.789886586462	0.794947748013	0.792295691349
Nurbf	n/a	0.75	0.806344264055	0.817267355844	0.811318054664
Nupoly	n/a	0.772727272727	0.746213615276	0.811223287157	0.764884959897
Nusigmoid	n/a	0.597402597403	0.515658075417	0.51594511139	0.515729122481


Note:
The underlying LinearSVC implementation uses a random number generator to select features when fitting the model. 
It is thus not uncommon, to have slightly different results for the same input data. If that happens, try with a smaller tol parameter.

Changing C with unweighted LinearSVC:
C	accuracy	precision	recall	f-score
100	0.451298701299	0.679658459678	0.702199891882	0.574176436855
10	0.688311688312	0.823845662653	0.789498995242	0.795807441144
1	0.782467532468	0.829508993405	0.826951953215	0.828202183947
.1	0.775974025974	0.770522651628	0.788119526948	0.777932993411
.01	0.75974025974	0.702181812017	0.746391113621	0.714918227243
.001	0.733766233766	0.642521883106	0.712096365927	0.651703597996
.0001	0.694805194805	0.616350310517	0.650453412836	0.621805689489
